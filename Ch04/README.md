# [Chater04 신경망 학습]
---
## 4.1 데이터에서 학습한다!
* 데이터에서 학습한다는 것은 가중치 매개변수의 값을 데이터를 보고 자동으로 결정한다는 뜻
* 데이터를 훈련 데이터와 시험 데이터로 나눠 학습과 실험을 수행하는 것이 일반적

## 4.2 손실 함수
* 손실 함수는 신경망 성능의 '나쁨'을 나타내는 지표, 현재의 신경망이 훈련 데이터를 얼마나 잘 처리하지 못하느냐를 나타낸다
* 가장 많이 쓰이는 손실 함수 -> 오차제곱합
![image](https://github.com/ehdtndla123/DeepLearning_from_scatch/assets/59868624/a2e97e65-af74-4b68-a32c-e6c84fb56b39)

* 오차제곱합 기준으로 추정 결과가 정답에 얼마나 가까운 것인지 판단할 수 있다
* 교차 엔트로피 오차 -> 정답일 때의 출력이 전체 값을 정하게 된다.
![image](https://github.com/ehdtndla123/DeepLearning_from_scatch/assets/59868624/e5da1696-da1b-47d6-a17d-3cbd1585d8e1)

> 미니배치
> 신경막 학습에서도 훈련 데이터로부터 일부만 골라 학습을 수애한다. 이 일부를 미니배치라고 한다. 가령 60000장의 훈련 데이터 중에서 100장을 무작위로 뽑아 그 100장
> 만을 사용하여 학습하는 것이다. 이러한 학습 방법을 미니배치 학습이라고 한다.

### 왜 손실 함수를 설정하는가?
* '미분'의 역할에 주목
* 신경망 학습에서는 최적의 매개변수를 탐색할 때 손실 함수의 값을 가능한 한 작게 하는 매개변수 값을 찾는다
* 정확도를 지표로 삼아서는 안 되는 이유는 미분 값이 대부분의 장소에서 0이 되어 매개변수를 갱신할 수 없기 때문이다
* 기울기가 0이 되지 않는 덕분에 신경이 올바르게 학습할 수 있다

## 4.3 수치 미분
* 경사법에서는 기울기 값을 기준으로 나아갈 방향을 정한다

## 4.4 기울기

## 4.5 학습 알고리즘 구현하기
0. 전제
* 신경망에는 적응 가능한 가중치와 편향이 있고, 이 가중치와 편향을 훈련 데이터에 적응하도록 조정하는 과정을'학습'이라고 한다. 신경망 학습은 4단계로 수행
1. 미니배치
* 훈련 데이터 중 일부를 무작위로 가져온다. 이렇게 선별한 데이터를 미니배치라 하며, 그 미니배치의 손실 함수 값을 줄이는 것이 목표이다.
2. 기울기 산출
* 미니배치의 손실 함수 값을 줄이기 위해 각 가중치 배개변수의 기울기를 구한다. 기울기는 손실 함수의 값을 가장 적게 하는 방향을 제시한다.
3. 배개변수 갱신
* 가중치 매개변수를 기울기 방향으로 아주 조금 갱신한다.
4. 반복
> 데이터를 미니배치로 무작위로 선정하기 때문에 **확률적 경사 하강법** 이라고 부른다.

> Epoch 훈련 데이터 10000개를 100개의 미니배치로 학습할 경우, 확률적 경사 하강법을 100회 반복하면 모든 훈련 데이터를 소진 -> 이경우 100회가 1에폭

* 1~3단계 반복
## 4.6 정리
* 기계학습에서 사용하는 데이터셋은 훈련 데이터와 시험 데이터로 나눠 사용한다.
* 훈련 데이터로 학습한 모델의 범용 능력을 시험 데이터로 평가한다.
* 신경망 학습은 손실 함수를 지표로, 손실 함수의 값이 작아지는 방향으로 가중치 매개변수를 갱신한다.
* 가중치 매개변수를 갱신할 때는 가중치 매개변수의 기울기를 이용하고, 기울어진 방향으로 가중치의 값을 갱신하는 작업을 반복한다.
* 아주 작은 값을 주었을 때의 차분으로 미분하는 것을 수치 미분이라고 한다.
* 수치 미분을 이용해 가중치 매개변수의 기울기를 구할 수 있다.
* 수치 미분을 이용한 계산에는 시간이 걸리지만, 그 구현은 간단하다. 한편, 다음 장에서 구현하는 (다소 복잡한) 오차역전파법은 기울기를 고속으로 구할 수 있다.
