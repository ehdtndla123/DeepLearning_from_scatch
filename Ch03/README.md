# [Chater03 신경망]
가중치 매개변수의 적절한 값을 데이터로부터 자동으로 학습하는 능력
## 3.1 퍼셉트론에서 신경망으로
![image](https://github.com/ehdtndla123/DeepLearning_from_scatch/assets/59868624/eb2bc377-cc0e-48d6-803c-b672e9a68c8b)

![image](https://github.com/ehdtndla123/DeepLearning_from_scatch/assets/59868624/bc1ade47-1877-4368-8fc3-3d9580a2287b)

* 활성화 함수란? 입력 신호의 총합을 출력 신호로 변환하는 함수 

## 3.2 활성화 함수
* 시그모이드 함수, 계단 함수, ReLU 함수
* 신경망에서 자주 이용하는 활성화 함수 **시그모이드 함수**
* 계단 함수와 시그모이드 함수는 비선형 함수이다
* 선형 함수 -> 층을 아무리 깊게 해도 '은닉층이 없는 네트워크'

## 3.3 다차원 배열의 계산

## 3.4 3층 신경망 구현하기

## 3.5 출력층 설계하기
* 신경망은 분류와 회귀 모두에 이용할 수 있다
* 어떤 문제냐에 따라 출력층에서 사용하는 활성화 홤수가 달라진다
* 분류에서 사용하는 소프트맥스 함수
![image](https://github.com/ehdtndla123/DeepLearning_from_scatch/assets/59868624/438a39a3-222b-420b-8c32-78164ba41020)
![image](https://github.com/ehdtndla123/DeepLearning_from_scatch/assets/59868624/eb99397f-e8e6-4d9e-8da6-21106d559b9c)
* 소프트 맥스 함수 구현 시, 지수 함수여서 오버플로 문제 가능성이 존재한다
* 소프트 맥스 함수의 특징 : 출력 총합이 1이다 -> 확률로 해석 가능

## 3.6 손글씨 숫자 인식
* 데이터를 특정 범위로 변환하는 처리 -> 정규화
* 신경망의 입력 데이터에 특정 변환을 가하는 것 -> 전처리
* 전처리를 통해 개선하고 학습 속도를 높인다.
> 배치 처리는 컴퓨터로 계산할 때 큰 이점을 준다. 첫번쨰로, 수치 계산 라이브러리 대부분이 큰 배열을 효율적으로 처리할 수 있도록 고도로 최적화되어 있기 때문이다. 두번째로, 커다란 신경망에서는 데이터 전송이 병목으로 작용하는 경우가 자주 있는데, 배치 처리를 수행함으로써 버스에 주는 부하를 줄인다.

## 3.7 졍리
*신경망에서는 활성화 함수로 시그모이드 함수와 ReLU 함수 같은 매끄럽게 변화하는 함수를 이용한다.
*넘파이의 다차원 배열을 잘 사용하면 신경망을 효율적으로 구현할 수 있다.
*기계학습 문제는 크게 회귀와 분류로 나눌 수 있다.
*출력층의 활성화 함수로는 회귀에서는 주로 항등 함수를, 분류에서는 주로 소프트맥스 함수를 이용한다.
*분류에서는 출력층의 뉴런 수를 분류하려는 클래스 수와 같게 설정한다.
*입력 데이터를 묶은 것을 배치라 하며, 추론 처리를 이 배치 단위로 진행하면 결과를 훨씬 빠르게 얻을 수 있다.
